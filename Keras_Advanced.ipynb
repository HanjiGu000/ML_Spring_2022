{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\E}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advanced Keras: motivation\n",
    "\n",
    "We have been using the Keras Model API (mostly the `Sequential`) as a black box.\n",
    "\n",
    "But it is highly customizable\n",
    "- A `Model` is a class (as in Python object)\n",
    "- It implements methods such as\n",
    "    - `compile`\n",
    "    - `fit`\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can change the behavior of a model in several ways\n",
    "- Arguments to some methods are objects; we can pass non-default functions/objects\n",
    "    - e.g., custom loss function\n",
    "- We can override these (and other) methods to make our models do new things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `Layer` is also an abstract class (Python) in Keras.\n",
    "\n",
    "Hence\n",
    "- We can create new layer types\n",
    "- We can override the methods of a given layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this module\n",
    "- we will\n",
    "illustrate techniques that you can use to customize your Layers/Models.\n",
    "- Illustrate the Functional model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Functional model: the basics\n",
    "\n",
    "The `Sequential` model\n",
    "- organizes layers as an ordered list\n",
    "- restricts the input to layer $(\\ll+1)$ to be the output of layer $ll$.\n",
    "\n",
    "The `Functional` model\n",
    "- imposes **no** ordering on layers\n",
    "- imposes **no** restriction on connect outputs of one layer to the input of another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To illustrate the `Functional` model let's take a first look\n",
    "at model implementing a single `Transformer` block\n",
    "- we will revisit this code later to illustrate other concepts\n",
    "\n",
    "Here is the picture of a Transformer block\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Transformer (Encoder/Decoder)</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Attention_is_all_u_need_Transformer.png\" width=50%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are actually 3 models in this cell we will visit !\n",
    "\n",
    "The Encoder side of the transformer:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This illustrates the pattern common to `Functional` models\n",
    "- The output of a layer is assigned to a variable (e.g., `encoder_inputs` has the value of the model's inputs)\n",
    "- The output of a layer is connected to the input of another layer via \"function call\" syntax\n",
    "    - e.g., `encoder_inputs` is applied as the input to the `PositionalEmbedding` layer\n",
    "        - `x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The collection (not necessarily a sequence) of `Layer` calls defines the mapping of\n",
    "`Model` inputs to outputs.\n",
    "\n",
    "To turn this collection into a `Model`\n",
    "- We define the inputs to the model\n",
    "- We define the output of the model\n",
    "\n",
    "But a `Model` is a complete mapping from the mini-batch examples to the function computed by the `Model`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, we define the Encoder side (sub-model of the Transformer) of the Transformer via\n",
    "\n",
    "    encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "    \n",
    "This defines `encoder` to be a `Model` with\n",
    "- input: `Layer` `encoder_inputs` (i.e., the `Input` layer)\n",
    "- output: `Layer` `encoder_outputs` (i.e., the `TransformerEncoder`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Note**: the input and output of a `Model` *don't have to be* `Layer` types !\n",
    "\n",
    "There is also a model for the Decoder side of the Transformer in the cell we will visit:\n",
    "\n",
    "    decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "- input: An **array**  of 2 `Layer` types -- `[ decoder_inputs, encoded_seq_inputs ]`\n",
    "- output: `Layer`: `decoder_outputs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Recall (from the Transformer picture) that the Decoder side consumes two inputs\n",
    "\n",
    "**pay close attention to the difference between $\\bar\\y$ (Encoder states) and $\\y$ (Decoder outputs)**\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Transformer Layer (Encoder/Decoder)</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Transformer_Encoder_Decoder.png\" width=70%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The output sequence $\\bar\\y_{(1..\\bar{T})}$ (i.e., latent states) of the Encoder\n",
    "    - Decoder-Encoder attention\n",
    "    - $|| \\bar\\y || = \\bar{T} = \\text{length of Transformer input}$\n",
    "- The prefix of the Decoder outputs generated up to time $\\tt$\n",
    "    - The Decoder output at time $(\\tt-1)$ is appended to the Decoder inputs available at time $\\tt$\n",
    "    - So the inputs are the Decoder outputs $\\y_{(1..T)}$\n",
    "        - $T$ is *full* length of Transformer output\n",
    "        - Causal (Masked) Attention is used to restrict the Decoder\n",
    "            - from attending at step $\\tt$ to any $\\y_\\tp$ where $\\tt > (\\tt-1)$\n",
    "            - Can't look at an output that hasn't been generated yet !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hence, the Decoder side takes a **pair** of inputs, as per the diagram.\n",
    "\n",
    "Let's see if we can trace which role each element of the pair serves.\n",
    "\n",
    "First, observe that the `Layer` sub-type `TransformerDecoder` actually implements the full Decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The second argument to `TransformerDecoder` has value `encoded_seq_inputs`\n",
    "- `encoded_seq_inputs` is the second argument passed to `decoder`.  See\n",
    "\n",
    "    decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "    \n",
    "- `decoder` is called with\n",
    "\n",
    "    decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "\n",
    "It would seem that `decoder_outputs` corresponds to $\\y$ in our picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thus, when `TransformerDecoder` is called\n",
    "\n",
    "    x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "    \n",
    "- The second argument to `TransformerDecoder` has value `encoded_seq_inputs = encoder_outputs`\n",
    "\n",
    "So it seems that second argument to `TransformerDecoder` is $\\bar\\y$, the latent states of the Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The first argument to `TransformerDecoder`, that is, the variable `x`\n",
    "- is positionally-encoded (to enable Causal masking) `decoder_inputs` \n",
    "\n",
    "    x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "\n",
    "Hopefully: `decoder_inputs` are the `decoder_outputs` shifted by one time step\n",
    "- The `PositionalEmbedding` is added to enforce Masking (causal ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, there is the Transformer Model, combining an Encoder and Decoder:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "transformer = keras.Model(\n",
    "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `transformer` first argument is `encoder_inputs`\n",
    "- which is the $\\x$ sequence in our picture (i.e., the input sequence)\n",
    "- `encoder_inputs` causes `encoder_outputs` to be generated\n",
    "- `encoder_outputs` ($\\bar\\y$ in our picture) is fed into the `decoder` generating `decoder_outputs` ($\\y$ in our picture), as described above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A lot going on here !\n",
    "- Hopefully:\n",
    "    - `decoder_inputs` is equal to `decoder_outputs` shifted by one time step\n",
    "    - Teacher forcing, enforced by the organization of the training data ?\n",
    "    \n",
    "- A complex connection of `Layer` outputs to inputs\n",
    "- Custom `Layer` sub-types\n",
    "    - `PositionalEmbedding`, `TransformerEncoder`, `TransformerDecoder`\n",
    "    - We will soon see how to define our own `Layer` sub-classes\n",
    "    \n",
    "Here is a first look at the [Transformer code](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/nlp/ipynb/neural_machine_translation_with_transformer.ipynb#scrollTo=hTc5eKn6aCHo&line=1&uniqifier=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model specialization\n",
    "\n",
    "## Custom loss (passing in a loss function)\n",
    "\n",
    "In introducing Deep Learning, we have asserted that\n",
    ">It's all about the Loss function\n",
    "\n",
    "That is: the key to solving many Deep Learning problems\n",
    "- Is not in devising a complex network architecture\n",
    "- But in writing a Loss function that captures the semantics of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Up until now\n",
    "- We have been  using pre-defined Loss functions (e.g., `binary_crossentropy`)\n",
    "- Specifying the Loss function in the compile statement\n",
    ">`model.compile(loss='binary_crossentropy')`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can [write your own loss functions](https://keras.io/api/losses/)\n",
    "\n",
    "In Keras, a Loss function has the signature\n",
    ">`loss_fn(y_true, y_pred, sample_weight=None)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Custom train step (override `train_step`)\n",
    "\n",
    "But what if your Loss function needs access to values that are not part of the signature ?\n",
    "\n",
    "Or what if you want to change the training loop ?\n",
    "\n",
    "You could write your own training loop by overriding the `fit` method\n",
    "- Cycle through epochs\n",
    "- Within each epoch, cycle through mini-batches of examples\n",
    "- For each mini-batch of examples: execute the *train step*\n",
    "    - forward pass: feed input examples to Input layer, obtain output\n",
    "    - compute the loss\n",
    "    - Compute the gradient of the loss with respect to the weights\n",
    "    - Update the weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Rather than overriding `fit`, it sometimes suffices to override the train step: `train_step`\n",
    "\n",
    "Let's start by looking at the \"standard\" implementation of a basic train step.\n",
    "\n",
    "We will see\n",
    "- How losses are computed\n",
    "- Gradients are obtained\n",
    "- Weights are updated\n",
    "\n",
    "[Basic `train_step`](https://colab.research.google.com/github/tensorflow/docs/blob/snapshot-keras/site/en/guide/keras/customizing_what_happens_in_fit.ipynb#scrollTo=9022333acaa7&line=1&uniqifier=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can modify the basic training step too.\n",
    "\n",
    "For example: suppose we want to make some training examples \"more important\" than others\n",
    "- Rather than Total Loss as equally-weighted average over all examples\n",
    "- Pass in per-example weights\n",
    "\n",
    "This might be useful, for example, when dealing with Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `Layer` specialization\n",
    "\n",
    "A `Layer` in Keras is an abstract (Python) object\n",
    "- instantiating the object returns a function\n",
    "    - That maps input to the layer to the output\n",
    "\n",
    "We have used specific instances of `Layer` objects (e.g., `Dense`) as arguments in the list passed to the `Sequential` model type.\n",
    "\n",
    "We can also use instances in the Functional Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example\n",
    "- `Dense(10)`\n",
    "    - Is the constructor for a fully connected layer instance with 10 units\n",
    "    - The constructor returns a function\n",
    "    - The the function maps the layer inputs to the outputs of the computation defined by the layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So you will see code fragments like\n",
    ">\n",
    "    x = Input(shape=(784))\n",
    "    x = Dense(10, activation=softmax)(x)\n",
    "    \n",
    "- Re-using the variable `x` as the output of the current layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When the function is invoked, the Layer's `call` method is used\n",
    "- `call` gets invoked implicitly by \"parenthesized argument\" juxtaposition\n",
    "    - e.g., `Dense(10) ( x )`\n",
    "    - is similar to `obj= `Dense(10); result = obj.call(x)`\n",
    "- The function maps the inputs to the layer to the output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Overriding `call` allows us to defined a new `Layer` sub-class.\n",
    "\n",
    "For example, [here](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/nlp/ipynb/neural_machine_translation_with_transformer.ipynb#scrollTo=AupqfNAYaCHn&line=2&uniqifier=1) is the code defining some new `Layer` types that will be used to create a `Transformer` layer type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The output of `Dense(10)` is a Tensor with final dimension equal to the number of units (e.g., 10)\n",
    "- The Tensor has leading dimensions too\n",
    "    - e.g., the implicit \"batch index\" dimension\n",
    "    - since the layer takes a mini-batch of examples (rather than a single example) as input\n",
    "- It may have *additional* dimensions too !\n",
    "    - Just like `numpy`: threading over additional dimensions\n",
    "    - e.g., if input is shape $(\\text{minibatch_size} \\times n_1 \\times n_2)$\n",
    "        - output is shape $(\\text{minibatch_size} \\times n_1 \\times 10)$\n",
    "        - `Dense` operates over the final dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Studying advanced models\n",
    "\n",
    "The best way to learn is to study the code of some non-trivial models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Factor Models and Autoencoders\n",
    "\n",
    "Here is an example of a Functional model applied to a common problem in Finance.\n",
    "- Functional model\n",
    "- Threading\n",
    "\n",
    "We will cover the Finance aspects of this in a [separate module](Autoencoder_for_conditional_risk_factors.ipynb)\n",
    "\n",
    "For now, I want to focus on the idea and the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Autoencoder for Conditional Risk Factors</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_for_conditional_risk_factors.png\" width=\"90%\"></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is the code, excerpted from the [notebook](https://github.com/stefan-jansen/machine-learning-for-trading/blob/main/20_autoencoders_for_conditional_risk_factors/06_conditional_autoencoder_for_asset_pricing_model.ipynb)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "def make_model(hidden_units=8, n_factors=3):\n",
    "    input_beta = Input((n_tickers, n_characteristics), name='input_beta')\n",
    "    input_factor = Input((n_tickers,), name='input_factor')\n",
    "\n",
    "    hidden_layer = Dense(units=hidden_units, activation='relu', name='hidden_layer')(input_beta)\n",
    "    batch_norm = BatchNormalization(name='batch_norm')(hidden_layer)\n",
    "    \n",
    "    output_beta = Dense(units=n_factors, name='output_beta')(batch_norm)\n",
    "\n",
    "    output_factor = Dense(units=n_factors, name='output_factor')(input_factor)\n",
    "\n",
    "    output = Dot(axes=(2,1), name='output_layer')([output_beta, output_factor])\n",
    "\n",
    "    model = Model(inputs=[input_beta, input_factor], outputs=output)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Autoencoder: Functional model\n",
    "\n",
    "\n",
    "<!--- #include (Autoencoder_example.ipynb)) --->\n",
    " [Autoencoder example from github](https://colab.research.google.com/github/kenperry-public/ML_Spring_2022/blob/master/Autoencoder_example.ipynb)\n",
    "- Functional model\n",
    "\n",
    "**Issues**\n",
    "- We could use a Sequential model with initial Encoder layers and final Decoder layers\n",
    "    - But we would not be able to independently access the Encoder nor the Decoder as isolated models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## VAE: Complex Loss; Manual Gradient updates\n",
    "\n",
    "[Variational Autoencoder (VAE) from github](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/vae.ipynb#scrollTo=DEU05Oe0vJrY)\n",
    "- Functional model\n",
    "- [VAE: Custom train step](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/vae.ipynb#scrollTo=0EHkZ1WCHw9E)\n",
    "    - Complex loss\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "**Issues**\n",
    "- Custom **model** (not layer) class VAE\n",
    "- The *reconstruction loss* depends on the output of the Decoder part of the VAE\n",
    "    - No other obvious way to define this loss aside from a **custom training** step\n",
    "- Because we are computing the Loss in the training step\n",
    "    - we must compute the gradient of the Loss wrt weights\n",
    "    - Update the weights (**gradient tape**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformer: Custom layers, Skip connections, Layer Norm\n",
    "\n",
    "[Transformer layer](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/nlp/ipynb/neural_machine_translation_with_transformer.ipynb#scrollTo=4DaEQr-lMkSs)\n",
    "- Functional model\n",
    "- Custom layers\n",
    "- Layer Norm\n",
    "- Skip connections\n",
    "\n",
    "The following diagram shows the architecture, which we can compare to the code\n",
    "- [Full architecture diagram (compare with code)](Transformer.ipynb#Full-Encoder-Decoder-Transformer-architecture)\n",
    "\n",
    "We can dig deeper to examine how the Attention layers are implemented in code:\n",
    "- [Scaled dot-product attention](https://www.tensorflow.org/text/tutorials/transformer#scaled_dot_product_attention)\n",
    "- [Multi-head attention](https://www.tensorflow.org/text/tutorials/transformer#multi-head_attention)\n",
    "\n",
    "\n",
    "\n",
    "**Issues**\n",
    "- Build a new layer type\n",
    "- Why are the components layers (e.g., Dense, MultiHeadAttention, LayerNormalization) instantiated in the class constructor\n",
    "    - As opposed to being defined in the \"call\" method \n",
    "    - Because we **need** one instance of the layer\n",
    "        - Not a new instance each time the class is \"called\" per batch\n",
    "            - This would result in brand new weights for each example batch\n",
    "    - The \"call\" method accesses the shared layer instances and performs the computation using them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Gradient Tape: Visualizing what CNN's learn\n",
    "\n",
    "[Visualizing what Convnets learn](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/visualizing_what_convnets_learn.ipynb#scrollTo=K8ITQAj7FTZd)\n",
    "- The Gradient Tape\n",
    "- Maximize utility (negative loss)\n",
    "    - mean (across the spatial dimensions) of one feature map in a multi-layer CNN\n",
    "    - the \"weights\" being solved for are the pixels of the input image !\n",
    "    \n",
    "[Gradient ascent](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/visualizing_what_convnets_learn.ipynb#scrollTo=a9hZnslRFTZZ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GAN\n",
    "[Simple GAN](https://keras.io/examples/generative/dcgan_overriding_train_step)\n",
    "- [Custom train step: GAN training](https://keras.io/examples/generative/dcgan_overriding_train_step/#override-trainstep)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wasserstein GAN with Gradient Penalty\n",
    "[Wasserstein GAN with Gradient Penalty](https://keras.io/examples/generative/wgan_gp/#create-the-wgangp-model)\n",
    "- [Gradient Tape: used for loss term, rather than weight update](https://keras.io/examples/generative/wgan_gp/#create-the-wgangp-model)\n",
    "- [Overide `compile`](https://keras.io/examples/generative/wgan_gp/#create-the-wgangp-model)\n",
    "- [Custom train step: GAN training](https://keras.io/examples/generative/wgan_gp/#create-the-wgangp-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural Style Transfer\n",
    "\n",
    "[Neural Style Transfer](https://keras.io/examples/generative/neural_style_transfer/)\n",
    "- [Complex Loss](](https://keras.io/examples/generative/neural_style_transfer/#compute-the-style-transfer-loss))\n",
    "- Custom training loop\n",
    "- [Feature extractor](https://keras.io/examples/generative/neural_style_transfer/#compute-the-style-transfer-loss)\n",
    "\n",
    "[Here](https://www.tensorflow.org/tutorials/generative/style_transfer) is a tutorial view of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
